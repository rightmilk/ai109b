# 第十三週筆記

## 反傳遞演算法
* 是「誤差反向傳播」的簡稱，是一種與最優化方法（如梯度下降法）結合使用的，用來訓練人工神經網絡的常見方法。該方法對網絡中所有權重計算損失函數的梯度。這個梯度會反饋給最優化方法，用來更新權值以最小化損失函數。

* 反向傳播要求有對每個輸入值想得到的已知輸出，來計算損失函數梯度。因此，它通常被認為是一種監督式學習方法，雖然它也用在一些無監督網絡（如自動編碼器）中。它是多層前饋網絡的Delta規則的推廣，可以用鏈式法則對每層疊代計算梯度。反向傳播要求人工神經元（或「節點」）的激勵函數可微。

* 三層網絡算法（只有一個隱藏層）：

    ```
    初始化網路權值（通常是小的隨機值）
    do
        forEach 訓練樣本 ex
            prediction = neural-net-output(network, ex)  // 正向傳遞
            actual = teacher-output(ex)
            計算輸出單元的誤差 (prediction - actual)
            計算    對於所有隱藏層到輸出層的權值 // 反向傳遞
            計算    對於所有輸入層到隱藏層的權值 // 繼續反向傳遞
            更新網路權值 // 輸入層不會被誤差估計改變
    until 所有樣本正確分類或滿足其他停止標準
    return 該網路

    ```


